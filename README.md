# Applied_AI_midterm_exam
This repository is for Applied AI midterm exam.

# Super Resolution GAN for Image Generation

## Table of Contents
1. [Introduction](#introduction)
2. [Dataset](#dataset)
3. [File Organization](#file-organization)
4. [Environment Setup](#environment-setup)
5. [How to Use the Code](#how-to-use-the-code)
6. [Model A: Binary Classifier](#model-a-binary-classifier)
7. [Model B: SRGAN](#model-b-srgan)
8. [Training Process](#training-process)
9. [Image Transformations](#image-transformations)
10. [Evaluation Metrics](#evaluation-metrics)
11. [Results](#results)
12. [Conclusion](#conclusion)
13. [License](#license)

## Introduction
This project implements a Super Resolution GAN (SRGAN) to augmented data for a binary classification task. The aim is to train a generator to produce high-resolution images and a discriminator to determine whether the images belonging to original datasets or generated by generator, ultimately using these data for improving the performance of a binary classifier.

## Dataset
- **Description**: Cats and dogs dataset. 
- **Access from kaggle**:  [Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats)

- **Data Preprocessing and Augmentation**: 

    All preprocessing code is in [data_precessing_and_.train_classifier_A.ipynb](data_precessing_and__train_classifier_A.ipynb)


    We apply several data augmentation and preprocessing techniques to enhance the diversity of the training data. The transformations include:
    1. **Resize**: Resize all images to `128x128`.
    2. **Random Rotation**: Randomly rotate images by Â±10 degrees.
    3. **Color Jitter**: Randomly adjust brightness, contrast, saturation, and hue.
    4. **Random Affine Transformation**: Randomly apply translation (up to 10%) and scaling (90%-110%).
    5. **Random Perspective**: Randomly apply perspective distortion with a 50% probability.
    6. **Random Horizontal Flip**: Randomly flip images horizontally.
    7. **ToTensor**: Convert images to PyTorch tensors.
    8. **Normalize**: Normalize images using ImageNet mean and std values.

These transformations help the model generalize better by introducing variability in the training data.

## File Organization

The project consists of the following files and directories:

- **`data_processing_and_train_classifier_A.ipynb`**  
  This Jupyter notebook handles data preprocessing, including downloading and preparing the "Cat and Dog" dataset. It also trains and evaluates **Classifier A**.

- **`train_classifier_B.ipynb`**  
  This Jupyter notebook use real dataset and fake dataset to train a binary classifier **Classifier B**.

- **`SRGANLOSS.py`**  
  This script contains the loss functions used for training the **SRGAN** model, including both the generator and discriminator loss functions.

- **`SRGAN.py`**  
  This script contains the architecture for the **SRGAN** model, which consists of the generator (G) and discriminator (D).

- **`SRGAN.ipynb`**  
  This Jupyter notebook implements the **SRGAN** training and evaluation pipeline. It trains the model, evaluates the results, and generates fake images.

- **`train_classifier_B.ipynb`**  
  This Jupyter notebook use real dataset and fake dataset to train a binary classifier **Classifier B**.


- **`requirements.txt`**  
  This file contains all the dependencies required for the project. Use `pip install -r requirements.txt` to install them.

- **`dataset/`**  
  This directory holds the datasets, including the original "Cat and Dog" dataset.

  **Note**: the dataset should be named as **`train.zip`**.

- **`training_results/`**  
    This directory holds the training results including the fake images generated from SRGAN.

## Environment Setup
- **Dependencies**:
    - `numpy` (>= 1.18.5)
    - `pandas` (>= 1.1.0)
    - `torch` (>= 1.7.0)
    - `tqdm` (>= 4.60.0)
    - `torchvision` (>= 0.8.0)
    - `pandas` (>= 1.1.0)
    - `scikit-learn` (>= 0.24.0)
    - `matplotlib` (>= 3.0.0)
    - `Pillow` (>= 8.0.0)

- **Setup Instructions**: 

```
pip install -r requirements.txt
```

## How to Use the Code  
### Step 1: Data Preprocessing and Classifier A Training
1. **Run `data_processing_and_train_classifier_A.ipynb`**:
   - This notebook will download and preprocess the "Cat and Dog" dataset.
   - It will train **Classifier A** on the preprocessed data and output the evaluation metrics.

### Step 2: Preparing Dataset for SRGAN
1. **Prepare the Dataset**:
   - Resize the images to 128x128 and create low-resolution images (32x32) from the high-resolution images (128x128). This is done in the `Midterm.ipynb` notebook.

### Step 3: Training SRGAN
1. **Train SRGAN**:
   - Run the training code in `Midterm.ipynb` to train the SRGAN. Make sure that both the generator and discriminator are trained with their respective learning rates.
   - After training, the SRGAN will generate 1000 fake cat and dog images.

### Step 4: Training Classifier B
1. **Train Classifier B**:
   - Combine the generated fake images with the original training set and train **Classifier B**.
   - Compare the performance of **Classifier A** and **Classifier B**.

---

## Classifier A and B
- **discreption**: These two classifiers have exactly the same structure which is used to determine whether a dog or cat is in a certain image.
- **Architecture**: Resnet18 with a binary outbut layer.
- **Transfer Learning**: 

    This project utilizes **transfer learning** with a pre-trained **ResNet-18** model, which has been trained on the ImageNet dataset. 

- **Training**: 
    - **Loss Function**: We use **Cross-Entropy Loss** for classification.
    - **Optimizer**: The model is optimized using the **Adam optimizer** with a learning rate of `0.0005`.


## Super-Resolution Generative Adversarial Network (SRGAN)
- **Architecture Overview**: Overview of the SRGAN architecture (generator and discriminator).
- **Training Process**: Explanation of the training process and hyperparameters used.
- **Image Generation**: Details on how the SRGAN is trained to generate images (32x32).

## Image Transformations
- **Normalization**: Description of normalization and other transformations applied to the images.
- **Examples**: Examples of transformed samples included.

## Evaluation Metrics

The following metrics were used to evaluate the models:

### 1. **Precision**
   - **Definition**: Precision is the ratio of correctly predicted positive observations to the total predicted positives.
   - **Formula**:  
     $$
     \text{Precision} = \frac{TP}{TP + FP}
     $$
     where:
     - $TP$ = True Positives (correctly predicted positive cases)
     - $FP$ = False Positives (incorrectly predicted positive cases)

### 2. **Recall (Sensitivity or True Positive Rate)**
   - **Definition**: Recall is the ratio of correctly predicted positive observations to all the actual positives.
   - **Formula**:  
     $$
     \text{Recall} = \frac{TP}{TP + FN}
     $$
     where:
     - \(TP\) = True Positives (correctly predicted positive cases)
     - \(FN\) = False Negatives (incorrectly predicted negative cases)

### 3. **F1-Score**
   - **Definition**: The F1-Score is the harmonic mean of Precision and Recall, providing a balance between the two. It is especially useful when the class distribution is imbalanced. The higher the F1-Score, the better the model performs in terms of both Precision and Recall.
   - **Formula**:  
     $$
     \text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
     $$
   - **Interpretation**: An F1-Score closer to 1 indicates better performance, while an F1-Score closer to 0 indicates poor performance.

### 4. **Support**

- Support refers to the number of actual occurrences of each class in the dataset. It provides context to the Precision, Recall, and F1-Score by showing how many samples belong to each class.
- Support is simply the count of instances for each class in the dataset.
### 5. **Macro Average** 

- The macro average is the arithmetic mean of Precision, Recall, and F1-Score for each class, without considering the class distribution. It gives an overall performance measure across all classes.

### 6. **Weighted Average**
 - The weighted average is the mean of the metrics (Precision, Recall, and F1-Score) calculated for each class, weighted by the number of instances in each class. This metric accounts for class imbalances and gives more weight to larger classes.

### 7.Confusion Matrix

- The confusion matrix is a summary table used to evaluate the performance of a classification model. It shows the counts of actual vs predicted values, and from these values, we can compute the Precision, Recall, and other metrics.


## Results
### Visual Examples

Visual examples of generated images from the SRGAN.

- cat

 <div style="display: flex; justify-content: center; gap: 10px;">
 <img src="training_results\high_res_data\0_cat.png" width=128>
<img src="training_results\fake_data\0_cat.png" width=128>
<img src="training_results\low_res_data\0_cat.png" width=128>

 <img src="training_results\high_res_data\1_cat.png" width=128>
<img src="training_results\fake_data\1_cat.png" width=128>
<img src="training_results\low_res_data\1_cat.png" width=128>
</div>

- dog

<div style="display: flex; justify-content: center; gap: 10px;">
 <img src="training_results\high_res_data\3_dog.png" width=128>
<img src="training_results\fake_data\3_dog.png" width=128>
<img src="training_results\low_res_data\3_dog.png" width=128>

<img src="training_results\high_res_data\7_dog.png" width=128>
<img src="training_results\fake_data\7_dog.png" width=128>
<img src="training_results\low_res_data\7_dog.png" width=128>
</div>

- From left to right: the original image, the low-resolution image, and the image generated by the generator.

- All generated images are stored in the `training_results/fake_data` directory. Due to the large volume of data, only 10 images are saved in this repository as examples.



#### Training Loss
- Classifier A and B

 <div style="display: flex; justify-content: space-between;">
<img src="imgs\Loss_A.png" width=400>
<img src="imgs\Loss_B.png" width=400>
</div>

The left one is the loss curve of the classifier A , while the right one for classifier B. 

- SRGAN

 <div style="display: flex; justify-content: space-between;">
<img src="imgs\generator_loss.png" width=400>
<img src="imgs\discriminator_loss.png" width=400>
</div>

The left one is the generator loss curve, while right one is the discriminator loss curve.

#### misclassification results  

Below are some images that were misclassified by both classifiers.



- classifier A

<img src="imgs\res_wrong_A.png" width=700/>

- classifier B

<img src="imgs\res_wrong_B.png" width=700 />

### Performance Comparison of two classifiers:

#### Precision, Recall, F1-score, Support, Accuracy, Macro Average and Weighted Average
- **Classifier A** 

    | Class           | Precision | Recall | F1-Score | Support |
    |-----------------|-----------|--------|----------|---------|
    | **0(cats)**     | 0.94      | 0.93   | 0.93     | 3752    |
    | **1(dogs)**     | 0.93      | 0.94   | 0.93     | 3748    |
    | **Accuracy**    |           |        | 0.93     | 7500    |
    | **Macro avg**   | 0.93      | 0.93   | 0.93     | 7500    |
    | **Weighted avg**| 0.93      | 0.93   | 0.93     | 7500    |
- **Classifier B** 

    | Class           | Precision | Recall | F1-Score | Support |
    |-----------------|-----------|--------|----------|---------|
    | **0 (cats)**    | 0.92      | 0.97   | 0.94     | 3752    |
    | **1 (dogs)**    | 0.97      | 0.91   | 0.94     | 3748    |
    | **Accuracy**    |           |        | 0.94     | 7500    |
    | **Macro avg**   | 0.94      | 0.94   | 0.94     | 7500    |
    | **Weighted avg**| 0.94      | 0.94   | 0.94     | 7500    |
- Confusion Matrix

    left one is for classifier A, while right one is for classifier B.

    <div style="display: flex; justify-content: space-between;">
  <img src="imgs\cm_A.png" width="370" />
  <img src="imgs\cm_B.png" width="370" />
    </div>


### Discussion & Conclusion

Using SRGAN for data augmentation can improve classifier performance to some extent, likely because the data generated by SRGAN significantly increases the diversity of the dataset. Moreover, SRGAN can learn the original distribution of the data, allowing the new training set to better represent the underlying distribution of the real cat and dogs image data.

## License

This project is licensed under the terms of the **GNU General Public License (GPL)** version 3.0. 

See the [LICENSE](LICENSE) file for details.

### GNU General Public License (GPL) v3.0

The GNU General Public License is a free software license that allows you to freely use, modify, and distribute the software. However, if you modify and distribute the software, you must share the source code under the same license, ensuring that any derivative works are also open source.

For more information about the GPL, you can visit the official website: [https://www.gnu.org/licenses/gpl-3.0.html](https://www.gnu.org/licenses/gpl-3.0.html)